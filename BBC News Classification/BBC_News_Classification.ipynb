{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBC News Classification\n",
    "\n",
    "_Completed as part of CU Boulder's **Unsupervised Algorithms in Machine Learning** course._\n",
    "\n",
    "This project uses both an unsupervised and a supervised model to predict the categories of a BBC news article dataset.\n",
    "\n",
    "The BBC news article dataset was provided on Kaggle here:\n",
    "https://www.kaggle.com/c/learn-ai-bbc/overview\n",
    "\n",
    "_Citation:_\n",
    "\n",
    "BBC. (2019, December). BBC News Classification, v1. Retrieved August 14, 2022 from https://www.kaggle.com/competitions/learn-ai-bbc/data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will import all needed dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import spacy\n",
    "import itertools\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# Vectorization libraries and configuration\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "train = pd.read_csv(\"data/BBC News Train.csv\")\n",
    "# There is an unlabelled test set available for the Kaggle competition\n",
    "# test = pd.read_csv(\"data/BBC News Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "First we will begin by looking the size of our data, features, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ArticleId                                               Text  Category\n",
      "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
      "1        154  german business confidence slides german busin...  business\n",
      "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
      "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
      "4        917  enron bosses in $168m payout eighteen former e...  business\n",
      "\n",
      "Train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train.head(5))\n",
    "print(\"\\nTrain:\")\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BBC news article train dataset is relatively small, with 1,490 articles for which there is only one feature, \"Text\", and our label is \"Category\".\n",
    "\n",
    "It looks like the article text has already been processed a bit, lowercasing content and removing some punctuation. We should also verify we don't have null values, and look at what content is contained in \"Text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticleId 0 0\n",
      "Text 0 0\n",
      "Category 0 0\n",
      "ArticleId 0 0\n",
      "Text 0 0\n"
     ]
    }
   ],
   "source": [
    "# Check for any null/null-like values\n",
    "null_like = [np.nan, None, [], {}, 'NaN', 'Null','NULL','None','NA','?','-', '.', '', ' ', '   ']\n",
    "\n",
    "for c in train.columns:\n",
    "    string_null = np.array([x in null_like for x in train[c]])\n",
    "    print(c, train[c].isnull().sum(), string_null.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28178\n",
      "Uncleaned, top 20 most frequent:\n",
      " ['the', '.', 'to', 'of', 'and', 'a', 'in', 's', 'for', 'is', 'that', 'it', 'on', 'said', 'was', 'he', 'be', 'with', 'has', 'as']\n"
     ]
    }
   ],
   "source": [
    "# Identify frequent work tokens to see what can be cleaned out\n",
    "word_freq_preview = defaultdict(int)\n",
    "\n",
    "for idx, article in train.iterrows():\n",
    "    text = article['Text']\n",
    "    for i in sent_tokenize(text):\n",
    "        temp = []\n",
    "        # tokenize the sentence into words\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j)\n",
    "            word_freq_preview[j] += 1\n",
    "print(len(word_freq_preview))\n",
    "word_freq_preview_sorted = sorted(word_freq_preview, key=word_freq_preview.get, reverse=True)\n",
    "print(\"Uncleaned, top 20 most frequent:\\n\", word_freq_preview_sorted[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 most frequent words:\n",
    "# ['the', '.', 'to', 'of', 'and', 'a', 'in', 's', 'for', 'is', 'that', 'it', 'on', 'said', 'was', 'he', 'be', 'with', 'has', 'as']\n",
    "# Lots of stop words, so we need to do some cleaning!\n",
    "\n",
    "# Using helpers from: https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial/notebook\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Removes stopwords and lemmatizes\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return ' '.join(txt)\n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in train['Text'])\n",
    "\n",
    "train['Clean Text'] = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The now clean text data needs to be prepared for interpretation. Simply passing arbitrary strings (each of which are unique) will not produce any results with matrix factorization methods - or most any machine learning methods without _some_ preprocessing.\n",
    "\n",
    "Now to prepare the data for training by tokenizing the text content, then it will be ready for using Word2Vec to produce vectors from word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for installing missing corpora if needed\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18437\n",
      "['worldcom', 'ex', 'boss', 'launch', 'defence', 'lawyer', 'defend', 'worldcom', 'chief', 'bernie', 'ebber', 'battery', 'fraud', 'charge', 'call', 'company', 'whistleblow', 'witness', 'cynthia', 'cooper', 'worldcom', 's', 'ex', 'head', 'internal', 'accounting', 'alert', 'director', 'irregular', 'accounting', 'practice', 'telecom', 'giant', 'warning', 'lead', 'collapse', 'firm', 'follow', 'discovery', 'bn', 'bn', 'accounting', 'fraud', 'mr', 'ebber', 'plead', 'guilty', 'charge', 'fraud', 'conspiracy', 'prosecution', 'lawyer', 'argue', 'mr', 'ebber', 'orchestrate', 'series', 'accounting', 'trick', 'worldcom', 'order', 'employee', 'hide', 'expense', 'inflate', 'revenue', 'meet', 'wall', 'street', 'earning', 'estimate', 'ms', 'cooper', 'run', 'consulting', 'business', 'tell', 'jury', 'new', 'york', 'wednesday', 'external', 'auditor', 'arthur', 'andersen', 'approve', 'worldcom', 's', 'accounting', 'early', 'say', 'andersen', 'give', 'green', 'light', 'procedure', 'practice', 'worldcom', 'mr', 'ebber', 's', 'lawyer', 'say', 'unaware', 'fraud', 'argue', 'auditor', 'alert', 'problem', 'ms', 'cooper', 'say', 'shareholder', 'meeting', 'mr', 'ebber', 'pass', 'technical', 'question', 'company', 's', 'finance', 'chief', 'give', 'brief', 'answer', 'prosecution', 's', 'star', 'witness', 'worldcom', 'financial', 'chief', 'scott', 'sullivan', 'say', 'mr', 'ebber', 'order', 'accounting', 'adjustment', 'firm', 'tell', 'hit', 'book', 'ms', 'cooper', 'say', 'mr', 'sullivan', 'mention', 'uncomfortable', 'worldcom', 's', 'accounting', 'audit', 'committee', 'meeting', 'mr', 'ebber', 'face', 'jail', 'sentence', 'year', 'convict', 'charge', 'face', 'worldcom', 'emerge', 'bankruptcy', 'protection', 'know', 'mci', 'week', 'mci', 'agree', 'buyout', 'verizon', 'communication', 'deal', 'value', 'bn'] ['hewitt', 'overcome', 'wobble', 'sydney', 'lleyton', 'hewitt', 'give', 'perfect', 'preparation', 'week', 's', 'australian', 'open', 'victory', 'ivo', 'minar', 'final', 'sydney', 'international', 'defend', 'champion', 'brush', 'aside', 'czech', 'qualifi', 'australian', 'world', 'number', 'stroll', 'game', 'match', 'shock', 'minar', 'win', 'seed', 'rattle', 'recover', 'close', 'set', 'race', 'victory', 'exactly', 'hour', 'strange', 'match', 'momentum', 'swing', 'say', 'hewitt', 'feel', 'like', 'come', 'block', 'extremely', 'loosen', 'bit', 'get', 'try', 'settle', 'notch', 'able', 'hewitt', 'lift', 'sydney', 'title', 'time', 'year', 'keep', 'get', 'well', 'well', 'year', 'hewitt', 'say', 've', 'play', 'tournament', 'time', 've', 'win', 'time', 'hewitt', 'go', 'final', 'short', 'price', 'favourite', 'clinch', 'th', 'career', 'title', 'drop', 'set', 'week', 'set', 'meet', 'frenchman', 'arnaud', 'clement', 'round', 'australian', 'open', 'minar', 'rank', 'th', 'world', 'force', 'pull', 'australian', 'open', 'qualifying', 'draw', 'play', 'atp', 'final', 'big', 'success', 'say', 'year', 'old', 'nervous', 'night', 'couldn', 't', 'sleep', 've', 'play', 'player', 'want', 'play', 'qualify', 'melbourne', 's', 'saturday', 'm', 'main', 'draw', 'need', 'point', 'money', 'alicia', 'molik', 'take', 'samantha', 'stosur', 'australian', 'woman', 's', 'final', 'later', 'saturday']\n"
     ]
    }
   ],
   "source": [
    "# Collect tokens for each article, and check frequent words \n",
    "# for verification of earlier cleaning\n",
    "tokens_by_idx = []\n",
    "word_freq = defaultdict(int)\n",
    "\n",
    "for idx, article in train.iterrows():\n",
    "    text = article['Clean Text']\n",
    "    for i in sent_tokenize(text):\n",
    "        temp = []\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j.lower())\n",
    "            word_freq[j.lower()] += 1\n",
    "        tokens_by_idx.append(temp)\n",
    "\n",
    "# With stop words, unique word count was 28,178\n",
    "print(len(word_freq))\n",
    "print(tokens_by_idx[0],tokens_by_idx[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most frequent:\n",
      " ['s', 'say', 'year', 'mr', 'new', 'people', 'm', 'good', 'win', 'time', 'game', 'film', 'world', 't', 'uk', 'come', 'government', 'play', 'go', 'work']\n"
     ]
    }
   ],
   "source": [
    "word_freq_sorted = sorted(word_freq, key=word_freq.get, reverse=True)\n",
    "print(\"Top 20 most frequent:\\n\", word_freq_sorted[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 'lawyer' <-> 'defence':  0.26813266\n",
      "Score 'lawyer' <-> 'economy': -0.097674064\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec model to build word embedding space\n",
    "bag_of_words_model = gensim.models.Word2Vec(tokens_by_idx, min_count=5, vector_size=100, window=3, epochs=50)\n",
    "\n",
    "# Print example similarity scores using embeddings\n",
    "print(\"Score 'lawyer' <-> 'defence': \", bag_of_words_model.wv.similarity('lawyer', 'defence'))\n",
    "print(\"Score 'lawyer' <-> 'economy':\", bag_of_words_model.wv.similarity('lawyer', 'economy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('economic', 0.5649333000183105),\n",
       " ('gdp', 0.5107204914093018),\n",
       " ('export', 0.507564127445221),\n",
       " ('manufacturing', 0.49129581451416016),\n",
       " ('inflation', 0.47642725706100464),\n",
       " ('growth', 0.4555329978466034),\n",
       " ('deficit', 0.4527810513973236),\n",
       " ('spending', 0.45186713337898254),\n",
       " ('recovery', 0.44436660408973694),\n",
       " ('lending', 0.44104188680648804)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further exploration of how well our bag of words model is associating words\n",
    "bag_of_words_model.wv.most_similar(positive=[\"economy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA: Word token distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x, y = zip(*sorted_counts[:300]) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y, color=\"purple\")\n",
    "plt.title(\"Word Token Frequency\")\n",
    "plt.xticks(np.arange(1, 300, 20.0), rotation = 65)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in preparing the document data for model training is to combine the word vectors for all words in an article to build an _article representation vector_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector combination based on: \n",
    "# https://blog.eduonix.com/artificial-intelligence/converting-word-vectors-document-vectors-using-gensim-library/\n",
    "doc_vectors = []\n",
    "min_val = 0\n",
    "\n",
    "for idx, article in train.iterrows():\n",
    "    tokens = tokens_by_idx[idx]\n",
    "    zero_vector = np.zeros(bag_of_words_model.vector_size)\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in bag_of_words_model.wv:\n",
    "            try:\n",
    "                vectors.append(bag_of_words_model.wv[token])\n",
    "            except KeyError:\n",
    "                continue\n",
    "    if vectors:\n",
    "        vectors = np.asarray(vectors)\n",
    "        avg_vec = vectors.mean(axis=0)\n",
    "        if min(avg_vec) < min_val:\n",
    "            min_val = min(avg_vec)\n",
    "        doc_vectors.append(avg_vec)\n",
    "    else:\n",
    "        doc_vectors.append(zero_vector)\n",
    "\n",
    "train_vectors = train[['ArticleId']].copy()\n",
    "train_vectors['Vectors'] = doc_vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing for NMF and Data Split\n",
    "\n",
    "In order to use non-negative matrix factorization, we must transform the document vector space to be only positive.\n",
    "\n",
    "After applying a simple transformation, time to split the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.0294478 , 1.7822278 , 1.7913359 , 1.9869816 , 2.2471411 ,\n",
      "       1.175039  , 1.2631197 , 2.1676593 , 1.8254151 , 2.209577  ,\n",
      "       1.4921206 , 1.4580877 , 1.4695758 , 1.7033094 , 1.5764331 ,\n",
      "       1.2054919 , 2.1016057 , 0.9348491 , 1.4811513 , 1.7826023 ,\n",
      "       1.3716033 , 1.9808426 , 1.8467771 , 2.0478828 , 1.554725  ,\n",
      "       1.5022445 , 1.8053565 , 1.8130747 , 1.4247305 , 1.6529782 ,\n",
      "       2.0060406 , 1.8174679 , 1.3908786 , 0.8671991 , 1.521924  ,\n",
      "       1.8911101 , 2.0668097 , 1.5490716 , 1.6389881 , 1.6885407 ,\n",
      "       1.9773983 , 1.4892023 , 1.6590594 , 0.98008937, 2.1197672 ,\n",
      "       2.0416214 , 1.1655856 , 1.2408166 , 1.8981702 , 1.76494   ,\n",
      "       1.8355918 , 1.4679788 , 1.7306923 , 1.3468164 , 1.801261  ,\n",
      "       2.333167  , 1.4316765 , 1.3878539 , 0.7408467 , 1.7303276 ,\n",
      "       0.8392912 , 1.5044818 , 1.9098284 , 1.6070253 , 1.2270792 ,\n",
      "       1.3656816 , 1.4048585 , 1.725655  , 1.5320965 , 1.7841626 ,\n",
      "       1.1127497 , 1.7764571 , 1.5163965 , 1.41823   , 1.3366011 ,\n",
      "       1.3983911 , 1.578377  , 2.1217146 , 1.2424632 , 1.4944407 ,\n",
      "       1.3503813 , 1.6974993 , 1.3903252 , 1.7072272 , 1.3458757 ,\n",
      "       1.4520583 , 1.2535107 , 1.9588331 , 1.83345   , 1.7695324 ,\n",
      "       1.5854468 , 1.4288849 , 1.8455843 , 1.6751251 , 1.7510023 ,\n",
      "       2.009763  , 2.0453596 , 1.2339718 , 1.5339859 , 1.4195888 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Shift all values to be positive\n",
    "pos_vectors = []\n",
    "for vector in doc_vectors:\n",
    "    pos_vectors.append(vector + abs(min_val))\n",
    "print(pos_vectors[:1])\n",
    "\n",
    "# split data for train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(pos_vectors, train[['Category']], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Model\n",
    "\n",
    "The target unsupervised model for this project will be using Non-Negative Matrix Factorization, effectively reducing latent features to 5 -- the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'tech' 'politics' 'sport' 'entertainment']\n"
     ]
    }
   ],
   "source": [
    "# We are looking to categorize into 5 labels\n",
    "print(train['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(beta_loss='kullback-leibler', init='nndsvda', l1_ratio=0.5, n_components=5,\n",
       "    random_state=57, solver='mu')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up and training NMF\n",
    "train_mat = csr_matrix(pos_vectors)\n",
    "nmf_mod = NMF(n_components=5, init='nndsvda', solver = 'mu', l1_ratio = 0.5, random_state = 57)\n",
    "nmf_mod.fit(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for evaluating unlabelled model output\n",
    "def predict(weights):\n",
    "    sortedW = np.argsort(weights)\n",
    "    k, maxValue = sortedW.shape\n",
    "    predictions = [[sortedW[i][maxValue - 1]] for i in range(k)]\n",
    "    topics = np.empty(k, dtype = np.int64)\n",
    "    for i in range(k):\n",
    "        topics[i] = predictions[i][0]\n",
    "    return topics\n",
    "\n",
    "# Matching model weights to labels\n",
    "def best_labels(df, y_pred):\n",
    "    \"\"\"\n",
    "    Returns label indices\n",
    "    Example output: (1,2,3,5,4), 0.5\n",
    "    \"\"\"\n",
    "    perms = list(itertools.permutations([0, 1, 2, 3, 4]))\n",
    "    categories = ['business','tech','politics','sport','entertainment']\n",
    "    acc = 0\n",
    "    best_perm = []\n",
    "    current = {}\n",
    "    for perm in perms:\n",
    "        for i in range(len(categories)):\n",
    "            current[categories[i]] = perm[i]\n",
    "            if len(current) == 5:\n",
    "                df['test'] = df['Category'].map(current)\n",
    "                current_accuracy = accuracy_score(df['test'], y_pred)\n",
    "                if current_accuracy > acc:\n",
    "                    df['Predicted'] = df['test']\n",
    "                    acc = current_accuracy\n",
    "                    best_perm = perm\n",
    "    df = df.drop(columns=[\"test\"])\n",
    "    return best_perm, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating on Word2Vec parameters\n",
    "\n",
    "Optimizing the word embedding space with the available parameters took several rounds of iteration. Below are some of the attempts and associated accuracy scores:\n",
    "\n",
    "```\n",
    "Parameters                                          Accuracy\n",
    "\n",
    "Using epochs: 5\n",
    "\n",
    "vector_size 50, window size: 4, min_count: 5        0.701\n",
    "vector_size 75, window size: 4, min_count: 5        0.700\n",
    "vector_size 100, window size: 3, min_count: 5       0.742\n",
    "vector_size 125, window size: 3, min_count: 5       0.710\n",
    "\n",
    "vector_size: 100, window size: 4, min_count: 5      0.714\n",
    "vector_size: 100, window size: 2, min_count: 5      0.672\n",
    "\n",
    "vector_size: 100, window size: 3, min_count 10      0.506\n",
    "vector_size: 100, window size: 3, min_count 3       0.6637\n",
    "\n",
    "Using vector_size: 100, window size: 3, min_count 5:\n",
    "\n",
    "epochs: 10      0.5711\n",
    "epochs: 20      0.700\n",
    "epochs 40       0.726\n",
    "epochs 50       0.759   # Winner\n",
    "epochs 60       0.726\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.7590604026845638\n"
     ]
    }
   ],
   "source": [
    "y_transform = predict(nmf_mod.transform(train_mat))\n",
    "label_order, accuracy = best_labels(train, y_transform)\n",
    "print('accuracy=', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further verification of the winning Word2Vec parameters on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.7384769539078156\n",
      "Test accuracy = 0.8008130081300813\n"
     ]
    }
   ],
   "source": [
    "x_train_mat = csr_matrix(x_train)\n",
    "x_test_mat = csr_matrix(x_test)\n",
    "nmf_mod_split = NMF(n_components=5, init='nndsvda', solver='mu', l1_ratio=0.5, random_state=57)\n",
    "nmf_mod_split.fit(x_train_mat)\n",
    "y_transform_train = predict(nmf_mod.transform(x_train_mat))\n",
    "label_order_train, train_accuracy = best_labels(y_train, y_transform_train)\n",
    "print('Train accuracy =', train_accuracy)\n",
    "y_transform_test = predict(nmf_mod.transform(x_test_mat))\n",
    "label_order_test, test_accuracy = best_labels(y_test, y_transform_test)\n",
    "print('Test accuracy =', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Supervised Model\n",
    "\n",
    "For comparison, previous experience has shown RandomForests to work well on smaller datasets with a reasonable feature space (at least less than number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest train accuracy: 0.998997995991984\n",
      "RandomForest test accuracy: 0.998997995991984\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(criterion=\"gini\", min_samples_split=8)\n",
    "rf_clf.fit(x_train, y_train['Category'])\n",
    "# Evaluate accuracy score\n",
    "rf_pred = rf_clf.predict(x_train)\n",
    "rf_score = accuracy_score(y_train['Category'], rf_pred)\n",
    "print('RandomForest train accuracy:', rf_score)\n",
    "\n",
    "rf_pred_test = rf_clf.predict(x_test)\n",
    "rf_score_test = accuracy_score(y_test['Category'], rf_pred_test)\n",
    "print('RandomForest test accuracy:', rf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using primarily default parameters RandomForest achieves almost perfect accuracy while still training quickly.\n",
    "\n",
    "For further comparison, we can also see how both approaches perform with a smaller training set, flipping the data split from 2/3 training data to 1/3 training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_small, x_test_big, y_train_small, y_test_big = train_test_split(pos_vectors, train[['Category']], test_size=0.60, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.7449664429530202\n",
      "Test accuracy = 0.7684563758389261\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised NMF\n",
    "x_train_mat = csr_matrix(x_train_small)\n",
    "x_test_mat = csr_matrix(x_test_big)\n",
    "nmf_mod_split = NMF(n_components=5, init='nndsvda', solver='mu', l1_ratio=0.5, random_state=57)\n",
    "nmf_mod_split.fit(x_train_mat)\n",
    "y_transform_train_small = predict(nmf_mod.transform(x_train_mat))\n",
    "label_order_train, train_accuracy = best_labels(y_train_small, y_transform_train_small)\n",
    "print('Train accuracy =', train_accuracy)\n",
    "y_transform_test_big = predict(nmf_mod.transform(x_test_mat))\n",
    "label_order_test, test_accuracy = best_labels(y_test_big, y_transform_test_big)\n",
    "print('Test accuracy =', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest train accuracy: 1.0\n",
      "RandomForest test accuracy: 1.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(criterion=\"gini\", min_samples_split=8)\n",
    "rf_clf.fit(x_train_small, y_train_small['Category'])\n",
    "\n",
    "rf_pred = rf_clf.predict(x_train_small)\n",
    "rf_score = accuracy_score(y_train_small['Category'], rf_pred)\n",
    "print('RandomForest train accuracy:', rf_score)\n",
    "\n",
    "rf_pred_test = rf_clf.predict(x_test_big)\n",
    "rf_score_test = accuracy_score(y_test_big['Category'], rf_pred_test)\n",
    "print('RandomForest test accuracy:', rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a smaller training set, neither model degrades, but surprisingly RandomForest actually achieves perfect accuracy.\n",
    "I would assume that this is due to overfitting to the dataset, and a larger dataset would be needed to develop a more general model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
